---
title: "HW6"
output: html_document
---
```{r}
library(readr)
library(ggplot2)
library(dplyr)
library(tidymodels)
library(ISLR)
library(tidyverse)
library(glmnet)
tidymodels_prefer()
library(rpart.plot)
library(vip)
library(janitor)
library(randomForest)
library(xgboost)
library(ranger)
```


# Question 1
```{r setup, include=FALSE}
Pokemon <- read_csv("~/Downloads/homework-6/data/Pokemon.csv")
Pokemon_clean <- clean_names(Pokemon)

#filter out by specific classes
Pokemon <- Pokemon_clean %>%
  filter(type_1 %in% c("Bug", "Fire", "Grass", "Normal", "Water", "Psychic"))

#factor type_1 and legendary
Pokemon$type_1 <- as.factor(Pokemon$type_1)
Pokemon$legendary <- as.factor(Pokemon$legendary)
View(Pokemon)

#split
set.seed(458)
Pokemon_split <- initial_split(Pokemon, strata = "type_1", prop = 0.7)
Pokemon_train <- training(Pokemon_split)
Pokemon_test <- testing(Pokemon_split)
dim(Pokemon_train)
dim(Pokemon_test)

#folds
pokemon_folds <- vfold_cv(Pokemon_train, v = 5, strata = "type_1")

#recipe
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + hp + sp_def, Pokemon_train) %>%
  step_dummy(c(legendary, generation)) %>%
  step_normalize(all_predictors())
```

# Question 2
```{r}
library(corrplot)
Pokemon_train %>%
  select(where(is.numeric)) %>%
  cor() %>% 
  corrplot(method = 'color')
```
In this plot, I have included all the continuous variables in order to see and study dependences or associations between the variables. This will help determine what makes the primary type of a specific Pokemon.

Looking at the relationships, there seems to be a strong positive relationship between total and all of the battle stats understandably, as the total sums up all the stats. However, it can also be noted that defense & sp_def, as well as attack & sp_attack are also relatively correlated. This again also makes sense, as both groups hold variables performing the same functions, but just towards a specific target.

# Question 3
```{r}
tree_spec <- decision_tree() %>%
  set_engine("rpart")

class_tree_spec <- tree_spec %>%
  set_mode("classification")

class_tree_fit <- class_tree_spec %>%
  fit(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + hp + sp_def, data=Pokemon_train)

class_tree_wf <- workflow() %>%
  add_model(class_tree_spec %>% set_args(cost_complexity = tune())) %>%
  add_formula(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + hp + sp_def)

poke_grid <- grid_regular(cost_complexity(range = c(-3, -1)), levels = 10)

tune_res <- tune_grid(
  class_tree_wf, 
  resamples = pokemon_folds, 
  grid = poke_grid, 
  metrics = metric_set(roc_auc)
)

autoplot(tune_res)
```

# Question 4
```{r}
arrange(collect_metrics(tune_res))
best <- select_best(tune_res, metric = "roc_auc")
best

```
The roc_auc of the best-performing pruned decision tree on the folds is 0.6388230.	

# Question 5
```{r}
tree_spec <- decision_tree() %>%
  set_engine("rpart")

class_tree_fit %>%
  extract_fit_engine() %>%
  rpart.plot(roundint=FALSE)

```


```{r}
rf_spec <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")
```
mtry = An integer for # of predictors that will be randomly sampled at each split when creating the tree models
trees = An integer for # of trees contained in the ensemble
min_n = An integer for the minimum # of data points in a node that are required for the node to be split further

```{r}
rf_spec2 <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")

class_tree_wf2 <- workflow() %>%
  add_recipe(pokemon_recipe) %>%
  add_model(rf_spec2)

grid2 = grid_regular(mtry(range=c(1,8)), trees(range=c(1,8)), min_n(range=c(1,8)),levels = 8)
```
Mtry should not be smaller than 1 or greater than 8 because the RF is based on a subset of the total number of predictors p (p/3). If you set mtry = 8, then you may see a huge variation in RMSEP between the different RF.

# Question 6
``` {r}
tune_res2 <- tune_grid(
  class_tree_wf2,
  resamples = pokemon_folds,
  grid = grid2,
  metrics = metric_set(roc_auc)
)

autoplot(tune_res2)

```
It appears as if the higher number of trees, the better performing the roc_auc. In all of the minimal node sizes, the higher number of trees continue to yield the best performance.

# Question 7
```{r}
arrange(collect_metrics(tune_res2))
best2 <- select_best(tune_res2, metric = "roc_auc")
best2
```
The roc_auc of my best performing random forest model is that of mtry =4, trees = 7, and min_n = 4; 0.7316887	

# Question 8
```{r}
vip(class_tree_fit)
```

# Question 9
```{r}
boost_spec <- boost_tree(trees= tune(), tree_depth = 4) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

boost_fit <- fit(boost_spec, type_1 ~ ., data = Pokemon_train)

grid3 = grid_regular(trees(range=c(10,2000)), levels = 10)

class_tree_wf3 <- workflow() %>%
  add_recipe(pokemon_recipe) %>%
  add_model(boost_spec)

tune_res3 <- tune_grid(
  class_tree_wf3,
  resamples = pokemon_folds,
  grid = grid3,
  metrics = metric_set(roc_auc)
)

autoplot(tune_res3)

arrange(collect_metrics(tune_res3))
best3 <- select_best(tune_res2, metric = "roc_auc")
best3
```
The roc_auc of the best-performing boosted tree model on the folds is that of model 244.

# Question 10
```{r}
values <- c()



```

